## O que √© "probabilidade condicional" e qual sua utilidade? üé≤

Probabilidade condicional se refere √† **probabilidade da ocorr√™ncia de um evento A**, dado que **sabemos que um evento B ocorreu**. Um exemplo simples √© quando temos um dado de seis faces e nos perguntamos qual a probabilidade de tirarmos o n√∫mero 2. Bom, se temos 6 n√∫meros igualmente poss√≠veis e queremos saber a probabilidade de tirarmos um deles (o n√∫mero 2), logo nossa probabilidade √© de $\frac{1}{6}$. 

Por√©m o que acontece se adicionarmos uma nova informac√£o ao problema? Vamos supor que agora temos dois dados. Algu√©m jogou o primeiro dado e nos disse que o resultado foi *um n√∫mero par*.
**Qual a probabilidade de obtermos o n√∫mero 2 ao jogar o segundo dado ap√≥s obter um n√∫mero par no primeiro dado?** Note que ambos os eventos s√£o *independentes*, ou seja, n√£o interferem um no outro, mas como agora temos uma combinac√£o de resultados, √© trivial imaginar que a probabilidade dessa combinac√£o vai ser menor do que a probabilidade de um ou outro evento separado. 

> [!TIP]  
> Ainda que contradit√≥rio, √© comum que as pessoas imaginem que a probabilidade de dois eventos A e B ocorrerem √© maior do que a probabilidade de somente A ou somente B. Veja: [Conjunction Fallacy](https://en.wikipedia.org/wiki/Conjunction_fallacy)

### Como encontrar a probabilidade condicional?
Para situac√µes desse tipo, temos uma equac√£o extremamente √∫til:
```math
P(A \mid B) = \frac{P(A \cap B)}{P(B)}
```
A probabilidade de A dado B √© igual a probabilidade de A e B sobre a probabilidade de B.
Substituindo os valores com o nosso exemplo do dado, obtemos:

> B = probabilidade de tirar um n√∫mero par no primeiro dado
> 
> A = probabilidade de tirar o n√∫mero 2 no segundo dado

```math
P(A \mid B) = \frac{P(\frac{1}{6} \cdot \frac{1}{2})}{P(\frac{1}{2})} = \frac{1}{6}
```

### Qual a diferenca entre a probabilidade de A e B, ou P(A,B) e a probabilidade de A dado B, ou P(A|B)?
![image](https://github.com/user-attachments/assets/d36db160-ad59-465f-b08d-a4f45c633e54) 

Na imagem[¬π](https://chrispiech.github.io/probabilityForComputerScientists/en/part1/cond_prob/) acima, temos 50 hex√°gonos no total. Esse √© o nosso _espaco amostral_, ou seja, todas as possibilidades existentes. A chance de termos E **e** F √© de $\frac{3}{50}$, se considerarmos _todos os 50 hex√°gonos_:
```math
P(E \cap F) = \frac{3}{50}
```
Contudo, quando queremos calcular a probabilidade de um evento acontecer **dado que outro evento j√° aconteceu**, nosso espaco amostral se torna reduzido: consideramos apenas o universo onde o primeiro evento ocorreu. Isso, no exemplo da imagem, significa que se quisermos calcular $P(E \mid F)$ estamos calculando a probabilidade de B dado que F ocorre:
```math
P(A \mid B) = \frac{P(\frac{3}{50})}{P(\frac{14}{50})} = \frac{3}{14} 
```
Ou seja, podemos pensar que a probabilidade condicional P(A|B) √© basicamente a probabilidade P(A,B) reduzida para o espaco amostral de B.

### Regra da cadeia

A f√≥rmula que vimos acima √© uma igualdade, ou seja, podemos obter a relacao abaixo a partir dela:
```math
P(B) \cdot P(A \mid B) = P(A \cap B)
```
Agora conseguimos encontrar a probabilidade de A e B ocorrerem se soubermos a probabilidade P(A | B)! Isso se torna extremamente √∫til quando falamos sobre a [lei da probabilidade total](https://en.wikipedia.org/wiki/Law_of_total_probability). Podemos visualizar como a f√≥rmula acima funciona utilizando √°rvores de decis√£o:

![decision tree](https://github.com/user-attachments/assets/8005a326-0a8b-4bed-8cce-00f80e48f1d7)

No exemplo acima[¬≤](https://www.youtube.com/watch?v=7t9jyikrG7w), temos tr√™s m√°quinas, e sabemos a probabilidade delas serem defeituosas. Por exemplo, sabemos que a chance da m√°quina 1 ser defeituosa √© 0.7. Isso seria equivalente a $P(D|M_{1}) = 0.7$. 
Dado que temos a probabilidade de a m√°quina 1 ser defeituosa, e sabemos a probabilidade de usar a m√°quina 1 ($P(M_{1}) = 0.6$), podemos multiplicar as probabilidades e obtemos 
```math
P(D \cap M_{1}) = P(M{1}) \cdot P(D \mid M_{1}) = 0.7 \cdot 0.5 = 0.35
```

### Refer√™ncias
1 - https://chrispiech.github.io/probabilityForComputerScientists/en/part1/cond_prob/

2 - https://www.youtube.com/watch?v=7t9jyikrG7w
