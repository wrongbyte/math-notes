# Teorema de Bayes: pensando com estat√≠stica üêà‚Äç‚¨õ

Suponha que tenhamos um dado de seis faces e o jogamos. 
Como temos 6 poss√≠veis resultados, e cada um desses resultados possui a mesma chance de ocorrer, a probabilidade de obtermos o n√∫mero 6 √© igual a $\frac{1}{6}$.

Contudo, podemos fazer outras perguntas com base nas informa√ß√µes que temos. Qual √© a probabilidade de jogarmos nosso dado **duas vezes** e obtermos o n√∫mero 6 **nas duas vezes**?
### Regras b√°sicas: adi√ß√£o e multiplica√ß√£o
Para resolver o problema acima, podemos utilizar de duas regras b√°sicas de probabilidade, que envolvem a _adic√£o_ de probabilidades e a _soma_ de probabilidades.
Quando temos interesse na probabilidade de dois eventos **independentes** ocorrerem, ou seja, A e B, multiplicamos a probabilidade de ocorr√™ncia de cada um desses eventos:
```math
 P\left ( A\cap B \right ) = P\left ( A \right ) P\left ( B \right )
```

> :bulb: Note que dois eventos s√£o independentes quando a probabilidade da ocorr√™ncia de um n√£o afeta a probabilidade de ocorr√™ncia do outro. Falaremos mais sobre em seguida.

Logo, a probabilidade de tirarmos o n√∫mero seis duas vezes √© igual a:
```math
P = \frac{1}{6} \cdot \frac{1}{6} = \frac{1}{36}
```

Ou seja, a chance de tirarmos o n√∫mero 6 duas vezes √© 1 em 36. Por√©m, podemos mudar de ideia e nos perguntar: qual √© a probabilidade de jogarmos nosso dado duas vezes e obtermos o **n√∫mero 6 ou o n√∫mero 2**?

Note que temos uma diferen√ßa fundamental: na primeira pergunta, est√°vamos buscando a **probabilidade da ocorr√™ncia de dois eventos.** Aqui estamos buscando a probabilidade de **um evento ou outro**, que nesse caso √© dada pela f√≥rmula:
```math
 P\left ( A\cup  B \right ) = P\left ( A \right ) + P\left ( B \right ) - P\left ( A  \cap  B \right )
```

Ent√£o vamos calcular a probabilidade de ocorr√™ncia de $$A\cup  B$$:

```math
P = \frac{1}{6} + \frac{1}{6} - \frac{1}{36}
```
Mas espere: ao jogar o dado uma vez, podemos ter o n√∫mero 6 **ou** o n√∫mero 2, sem a possibilidade de obtermos dois n√∫meros **ao mesmo tempo.** Isso, na pr√°tica, significa que nossos dois eventos s√£o **mutuamente exclusivos** e portanto n√£o podemos ter a ocorr√™ncia de ambos ao mesmo tempo. Em suma, isso significa que $$P\left ( A  \cap  B \right ) = 0$$.
Ou seja:

```math
P = \frac{1}{6} + \frac{1}{6} = \frac{2}{3}
```
A probabilidade de tirarmos 2 ou 6 no nosso dado √© $$\frac{2}{3}$$.

## Fazendo perguntas mais complexas
Suponha que agora temos dois dados. Jogamos o primeiro dado e ele nos d√° um n√∫mero par.
Agora, jogamos o segundo dado e ele nos d√° o n√∫mero 2. Qual a probabilidade dessa situac√£o ocorrer?

### Probabilidade condicional
Note que no √∫ltimo exemplo, o fato de reduzirmos os resultados poss√≠veis a _apenas os n√∫meros pares_ influenciou diretamente na probabilidade de obtermos o n√∫mero 2. Ela dobrou!
Temos nesse caso um exemplo de **probabilidade condicional**. A f√≥rmula para encontrarmos a probabilidade $P(A \mid B)$ √© a seguinte:

```math
P(A \mid B) = \frac{P(A \cap B)}{P(B)}
```
> :bulb: PS: a notac√£o $$P(A \mid B)$$ significa **a probabilidade de A dado B**. Por exemplo, a probabilidade de termos tirarmos o n√∫mero 2 **dado que** o n√∫mero que tiramos no primeiro dado √© par.

Observe a f√≥rmula acima. Ela nos indica que a probabilidade de A, dado B, √© igual a probabilidade da ocorr√™ncia de **A e B** sobre a probabilidade da ocorr√™ncia de B. Nessa equac√£o, **assumimos que o evento B ocorreu**, ou seja, nosso espa√ßo amostral se torna reduzido. Podemos dizer que essa √© uma _probabilidade a posteriori_, ou seja, uma probabilidade calculada ap√≥s sabermos novas informac√µes.

### Usando a f√≥rmula para calcular um caso simples
Vamos imaginar mais um cen√°rio com nosso dado de seis faces. 
Agora, vamos definir dois eventos.

Vamos definir P(A) como sendo a probabilidade de obtermos algum n√∫mero que pertenca ao conjunto A:
```math
A = \left\{ 1,2,3,4,5\right\} 
```
Podemos seguir a mesma l√≥gica com o conjunto B:
```math
B = \left\{3,4,5,6\right\} 
```
Agora vamos nos perguntar: qual o valor de $P(A \mid B)$?

Voc√™ pode ter percebido que esse √© um caso t√£o simples que n√£o necessita que usemos a f√≥rmula da probabilidade condicional, afinal se o evento B ocorreu, sabemos que nosso n√∫mero est√° no conjunto B, podendo ser 3,4,5 ou 6.
Nosso espaco amostral ent√£o se reduz ao conjunto B. Para calcular a probabilidade do evento A nesse cen√°rio, devemos considerar que s√≥ os n√∫meros {3,4,5} aparecem em B. Portanto, usando esse racioc√≠nio chegamos no resultado:
```math
P(A \mid B) = \frac{3}{4}
```
O que fizemos, indiretamente, foi seguir o mesmo passo a passo da f√≥rmula da probabilidade condicional:
```math
P(A \cap B) = \frac{3}{6}
```

```math
P(A \mid B) = \frac{P(A \cap B)}{P(B)} = \frac{\frac{3}{6}}{\frac{4}{6}} = \frac{3}{4}
```

## O teorema de Bayes
A f√≥rmula da probabilidade condicional que vimos possui uma propriedade interessante. Ao colocarmos a probabilidade da ocorr√™ncia de A e B em evid√™ncia [(regra da cadeia)](https://github.com/wrongbyte/math-notes/blob/main/pt/chain-rule.md):
```math
P(A \cap B) = P(B) \cdot P(A \mid B)
```
[Notamos que](https://www.hep.upenn.edu/~johnda/Papers/Bayes.pdf):
```math
P(B) \cdot P(A \mid B) = P(A) \cdot P(B \mid A)
```
e com isso chegamos na seguinte igualdade, tamb√©m chamada de **teorema de Bayes**:
```math
P(A \mid B) = \frac{P(A) \cdot P(B \mid A)}{P(B)}
```

Essa f√≥rmula √© equivalente a f√≥rmula da probabilidade condicional, e ambas s√£o usadas para calcularmos a probabilidade da ocorr√™ncia de um evento quando sabemos da ocorr√™ncia de outro evento. A diferenca fundamental √© que a f√≥rmula de Bayes nos d√° uma relac√£o que utiliza de outra probabilidade condicional. Parece muito abstrato? Vamos ver a aplicac√£o em alguns exemplos.

## Antes de prosseguir: a po√ß√£o da probabilidade total üîÆü™Ñ
Agora que j√° sabemos o que √© probabilidade condicional e como calcul√°-la, √© hora de imaginar um cen√°rio curioso: suponhamos que exista uma "po√ß√£o m√°gica da verdade". Essa po√ß√£o √© usada para descobrir quem √© culpado de algum crime;

![potion](https://community.akamai.steamstatic.com/economy/image/a5HYp9Sw61Iks7TiNF57DFqT7uTUsBt13CvwcWpsxqwUkg/360fx360f)

Contudo, esta po√ß√£o tem um funcionamento espec√≠fico: **ela funciona 90% das vezes quando aplicada em uma pessoa culpada e 99% das vezes quando aplicada em uma pessoa inocente**. Um suspeito √© retirado de um grupo de pessoas, onde 95% jamais cometeram qualquer crime.

Dito isso, temos duas perguntas a responder:

**1 - Qual √© a probabilidade de a po√ß√£o nos dar a resposta certa?**

**2 - Se a po√ß√£o indica ‚Äúculpado‚Äù, qual √© a probabilidade de o suspeito ser
inocente?**


Nesse cen√°rio, temos os seguintes eventos poss√≠veis:

- $C$ = "suspeito culpado"
- $\bar{C}$ = "suspeito inocente"
- $V$ = "po√ß√£o indicou que o suspeito √© culpado"
- $\bar{V}$ = "po√ß√£o indicou que o suspeito √© inocente"

> :bulb: A notac√£o $\bar{A}$ significa o *complementar* do evento $A$, que √© basicamente o evento "n√£o A". Por exemplo, se definirmos $A$ como obter cara no lan√ßamento de uma moeda, $\bar{A}$ seria obter coroa. Note que isso implica que os eventos $A$ e $\bar{A}$ s√£o **mutuamente exclusivos**.

Vamos come√ßar representando os eventos acima em uma √°rvore:

![√°rvore das probabilidades](https://dev-to-uploads.s3.amazonaws.com/uploads/articles/bq4v7gy3mtv0atliwh0c.png)

Os cen√°rios onde a poc√£o nos d√° as respostas certas s√£o os destacados em amarelo:

![image](https://github.com/user-attachments/assets/c8481beb-2aa4-4357-9882-e917074de807)

Ou seja, a probabilidade total de termos o resultado correto √© a soma da probabilidade dos dois caminhos acima (pois s√£o caminhos mutuamente exclusivos).

```math
P(A) = P(C \cap V) \cup P(\overline{C} \cap \overline{V})
```

Sabemos que a probabilidade da poc√£o funcionar em um suspeito inocente - $P(\overline{C} \mid \overline{V})$ - √© de 99%, e a probabilidade de funcionar em um suspeito culpado - $P(C \mid V)$ - √© de 99%. Veja que temos as probabilidades _condicionais_, mas n√£o temos as probabilidades $P(C \cap V)$ e $P(\overline{C} \cap \overline{V})$. Como encontr√°-las?

### Regra da cadeia
Dado a f√≥rmula da probabilidade condicional,
```math
P(A \mid B) = \frac{P(A \cap B)}{P(B)}
```
temos a seguinte igualdade:
```math
P(A \cap B) = P(B) \cdot P(A \mid B)
```

Ou seja, 
```math
P(V \cap C) = P(C) \cdot P(V \mid C) = 0.05 \cdot 0.90 = 0.045
```
Outra forma de visualizar isso √© transformando nossa √°rvore de decis√£o em um grafo ponderado:

![image](https://github.com/user-attachments/assets/c450057a-4326-480b-b996-4970430804cc)

Para sabermos a probabilidade $P(C \cap V)$ multiplicamos os valores de suas arestas, ou seja, $0.05 \cdot 0.90$, que √© o equivalente a termos usado a regra da cadeia.
Fazendo o mesmo para $P(\overline{C} \cap \overline{V})$:
```math
P(\overline{V} \cap \overline{C}) = P(\overline{C}) \cdot P(\overline{V} \mid \overline{C}) = 0.95 \cdot 0.99 = 0.9405
```

Somando ambas as probabilidades, obtemos $0.9855$. Ou seja, temos 98,5% de chance de obter o resultado correto com a nossa poc√£o.

### Lei da probabilidade total
A regra da cadeia √© extremamente √∫til na **lei da probabilidade total**.
Com as informacoes que temos, podemos nos perguntar: **qual a probabilidade da nossa pocao apontar que um suspeito √© culpado**? 
Veja que s√≥ sabemos as probabilidades condicionais: os valores 90% e 99% s√£o de eventos _condicionados_, ou seja, dependem da probabilidade _a priori_, que √© o suspeito ser culpado ou n√£o. Por√©m, aqui queremos saber a probabilidade **sem saber se o suspeito √© culpado ou n√£o**. Como encontrar esse n√∫mero?

Considerando P(V) como a probabilidade da pocao apontar que o suspeito √© culpado:
```math
P(V) = P(C) \cdot P(V \mid C) + P(\overline{C}) \cdot P(V \mid \overline{C})
```
```math
P(V) = 0.05 \cdot 0.90 + 0.95 \cdot 0.01 = 0.0545
```
ou seja, temos 5,45% de chance da nossa poc√£o indicar que algum suspeito √© culpado.
Esse c√°lculo √© a base da **lei da probabilidade total**:
```math
P(A) = P(A\cap B) + P(A \cap \overline{B})
```
utilizando a regra de cadeia:
```math
P(A) = P(B) \cdot P(A\mid B) + P(\overline{B}) \cdot P(A \mid \overline{B})
```

que pode ser generalizado para:
```math
P(A) = \sum_{i=1}^{n} P(A \mid B_i) \cdot P(B_i)
```

## Exemplos pr√°ticos com o Teorema de Bayes
Pense no seguinte problema:
> Uma pessoa usa seu carro 30% do tempo, anda a p√© 30% do tempo e pega o √¥nibus 40% do tempo para ir ao trabalho. Ele se atrasa 10% das vezes quando anda a p√©; ele se atrasa 3% das vezes quando dirige; e se atrasa 7% das vezes que pega o √¥nibus.

1 - Qual √© a probabilidade de que ele tenha pego o √¥nibus, dado que se atrasou?

2 - Qual √© a probabilidade de que ele tenha andado a p√©, dado que chegou no hor√°rio?

<hr>
Vamos definir os **eventos**:

- W: a pessoa foi ao trabalho andando
- C: a pessoa foi ao trabalho de carro
- B: a pessoa foi ao trabalho de √¥nibus
- L: a pessoa se atrasou
- $\overline{L}$: a pessoa chegou no hor√°rio

Probabilidades **conhecidas**:

- P(W) = 0,3: 30% das vezes ele vai andando.
- P(C) = 0,3: 30% das vezes ele vai de carro.
- P(B) = 0,4: 40% das vezes ele vai de √¥nibus.
- P(L|W) = 0,1: Ele se atrasa 10% das vezes que vai andando.
- P(L|C) = 0,03: Ele se atrasa 3% das vezes que vai de carro.
- P(L|B) = 0,07: Ele se atrasa 7% das vezes que vai de √¥nibus.


1. Qual √© a probabilidade de que ele tenha pego o √¥nibus, dado que se atrasou?
Queremos encontrar P(B‚à£L).

Pelo Teorema de Bayes:
```math
P(B|L) = \frac{P(L|B) \cdot P(B)}{P(L)}
```

Primeiro, precisamos encontrar P(L), a probabilidade de que ele se atrase. Esta √© a probabilidade total de ele se atrasar, considerando todas as formas de transporte:

```math
P(L) = P(L|W) \cdot P(W) + P(L|C) \cdot P(C) + P(L|B) \cdot P(B)
```

Substituindo os valores:

```math
P(L) = (0,1 \cdot 0,3) + (0,03 \cdot 0,3) + (0,07 \cdot 0,4)
```
```math
P(L) = 0,03 + 0,009 + 0,028 = 0,067
```
Agora, substitu√≠mos na f√≥rmula de Bayes para encontrar P(B‚à£L):

```math
P(B|L) = \frac{P(L|B) \cdot P(B)}{P(L)}
```
```math
P(B|L) = \frac{0,07 \cdot 0,4}{0,067}
```
```math
P(B|L) \approx \frac{0,028}{0,067} \approx 0,418
```

Portanto, a probabilidade de que ele tenha pego o √¥nibus, dado que se atrasou, √© aproximadamente 41,8%.
A segunda quest√£o fica como exerc√≠cio para o leitor.

### Refer√™ncias
[Lista de exerc√≠cios na √≠ntegra](https://mathcenter.oxford.emory.edu/site/math117/probSetBayesTheorem/)

https://byjus.com/maths/multiplication-rule-probability/#:~:text=What%20is%20the%20Multiplication%20Rule,given%20that%20event%20B%20occurs.

https://www.hep.upenn.edu/~johnda/Papers/Bayes.pdf

https://cesad.ufs.br/ORBI/public/uploadCatalago/10161710102012Probabilidade_e_Estatistica_aula_9.pdf
